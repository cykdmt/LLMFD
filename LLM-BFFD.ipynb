{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f41405f-8c56-4899-a854-8cb260374f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel  \n",
    "import torch  \n",
    "\n",
    "max_seq_length = 2048 \n",
    "dtype = None  \n",
    "load_in_4bit = True  \n",
    "\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"./model_cache\",  \n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d66431-d25c-4960-aea2-a31e9f0e59f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_style = \"\"\"The following is a task description along with contextual input.\n",
    "Please provide an appropriate answer, and before answering, perform logical reasoning to support your judgment.\n",
    "\n",
    "### Instruction:\n",
    "You are a professional blast furnace equipment fault diagnosis expert. \n",
    "You have mastered the various states and causes of the blast furnace operation process, and can accurately determine the blast furnace operation state according to the given variables and their values. \n",
    "\n",
    "The operational status of the blast furnace includes the following five categories:\n",
    "- Normal state, label: 0.0\n",
    "- Fault category: Hanging, fault label: 1.0\n",
    "- Fault category: Hot Stove Malfunction, fault label: 2.0\n",
    "- Fault category: Channeling, fault label: 3.0\n",
    "\n",
    "You need to analyze the data according to the causes of various fault states to determine the system is in the normal state or which of the four fault states.\n",
    "\n",
    "### Question:\n",
    "{}\n",
    "\n",
    "### Answer:\n",
    "\n",
    "\n",
    "Your reasoning:\n",
    "<think>{}\"\"\"\n",
    "\n",
    "\n",
    "question = '''{\n",
    "    \"Question\": \"\"\n",
    "}'''\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "\n",
    "import json\n",
    "question_text = json.loads(question)[\"Question\"]  \n",
    "\n",
    "inputs = tokenizer(\n",
    "    [prompt_style.format(question_text, \"\")],  \n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=2650,\n",
    "    use_cache=True,\n",
    ")\n",
    "\n",
    "response = tokenizer.batch_decode(outputs)\n",
    "print(response[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e80d4b-394a-4c5c-b6d0-e93e57d7ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompt_style = \"\"\"The following is a task description along with contextual input.\n",
    "Please provide an appropriate answer, and before answering, perform logical reasoning to support your judgment.\n",
    "\n",
    "### Instruction:\n",
    "You are a professional blast furnace equipment fault diagnosis expert. \n",
    "You have mastered the  various states and causes of the blast furnace operation process, and can accurately determine the blast furnace operation state according to the given variables and their values. \n",
    "﻿\n",
    "The operational status of the blast furnace includes the following five categories:\n",
    "- Normal state, label: 0.0\n",
    "- Fault category: Hanging, fault label: 1.0\n",
    "- Fault category: Hot Stove Malfunction, fault label: 2.0\n",
    "- Fault category: Channeling, fault label: 3.0\n",
    "﻿\n",
    "You need to analyze the data according to the causes of various fault states to determine the system is in the normal state or which of the four fault states.\n",
    "\n",
    "### Question:\n",
    "{}\n",
    "\n",
    "### Answer:\n",
    "<think>\n",
    "{}\n",
    "\n",
    "</think>\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token  \n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"/root/traindataset.jsonl\", trust_remote_code=True)\n",
    "\n",
    "print(dataset.column_names)\n",
    "def formatting_prompts_func(examples):\n",
    "    inputs = examples[\"input\"]\n",
    "    cots = examples[\"reasoning\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    texts = []  \n",
    "    for input, cot, output in zip(inputs, cots, outputs):\n",
    "        text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n",
    "        texts.append(text)  \n",
    "    return {\n",
    "        \"text\": texts,  \n",
    "    }\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True)\n",
    "dataset[\"text\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3a46c6-77b3-450a-ac3b-d1708becd894",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_training(model)\n",
    "\n",
    "\n",
    "# Attn-only\n",
    "attn_only = [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"]\n",
    "\n",
    "# Attn+FFN\n",
    "attn_ffn = [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"]\n",
    "\n",
    "# FFN-only\n",
    "ffn_only = [\"gate_proj\",\"up_proj\",\"down_proj\"]\n",
    "\n",
    "\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,  \n",
    "    r = 16,  \n",
    "    target_modules = attn_only,\n",
    "    lora_alpha = 32,  \n",
    "    lora_dropout = 0.1,  \n",
    "    bias = \"none\",   \n",
    "    use_gradient_checkpointing = \"unsloth\",  \n",
    "    random_state = 3407,  \n",
    "    use_rslora = False,  \n",
    "    loftq_config = None,  \n",
    ")\n",
    "\n",
    "from trl import SFTTrainer  \n",
    "from transformers import TrainingArguments  \n",
    "from unsloth import is_bfloat16_supported  \n",
    "\n",
    "trainer = SFTTrainer(  \n",
    "    model=model,  \n",
    "    tokenizer=tokenizer,  \n",
    "    train_dataset=dataset,  \n",
    "    dataset_text_field=\"text\",  \n",
    "    max_seq_length=max_seq_length,  \n",
    "    dataset_num_proc=2,  \n",
    "    packing=False,  \n",
    "    args=TrainingArguments(  \n",
    "        per_device_train_batch_size=2,  \n",
    "        gradient_accumulation_steps=4,  \n",
    "        warmup_steps=10,  \n",
    "        num_train_epochs=30,  \n",
    "        learning_rate=2e-4,  \n",
    "        fp16=not is_bfloat16_supported(),  \n",
    "        bf16=is_bfloat16_supported(),  \n",
    "        logging_steps=20,  \n",
    "        optim=\"adamw_8bit\",  \n",
    "        weight_decay=0.1,  \n",
    "        lr_scheduler_type=\"linear\",  \n",
    "        seed=3407,  \n",
    "        output_dir=\"outputs\",  \n",
    "        report_to=\"none\",  \n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer_stats = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a4ac0-c6d7-4e92-be02-8ef64d66c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "eval_dataset = load_dataset(\"json\", data_files=\"/root/testdataset.jsonl\")\n",
    "\n",
    "\n",
    "prompt_style =  \"\"\"The following is a task description along with contextual input.\n",
    "Please provide an appropriate answer, and before answering, perform logical reasoning to support your judgment.\n",
    "\n",
    "### Instruction:\n",
    "You are a professional blast furnace equipment fault diagnosis expert. \n",
    "You have mastered the  various states and causes of the blast furnace operation process, and can accurately determine the blast furnace operation state according to the given variables and their values. \n",
    "﻿\n",
    "The operational status of the blast furnace includes the following five categories:\n",
    "- Normal state, label: 0.0\n",
    "- Fault category: Hanging, fault label: 1.0\n",
    "- Fault category: Hot Stove Malfunction, fault label: 2.0\n",
    "- Fault category: Channeling, fault label: 3.0\n",
    "\n",
    "You need to analyze the data according to the causes of various fault states to determine the system is in the normal state or which of the four fault states.\n",
    "\n",
    "### Question:\n",
    "{}\n",
    "\n",
    "### Answer:\n",
    "<think>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "pred_labels = []\n",
    "true_labels = []\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for example in tqdm(eval_dataset):\n",
    "    question = example[\"input\"]\n",
    "    label = str(example[\"output\"])\n",
    "    input_text = prompt_style.format(question)\n",
    "    inputs = tokenizer([input_text], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "   \n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_new_tokens=2650,\n",
    "    )\n",
    "\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model_output = model(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask, output_hidden_states=True)\n",
    "        hidden_states = model_output.hidden_states[-2]  \n",
    "        mean_hidden = hidden_states.mean(dim=1)  # shape: [batch_size, hidden_dim]\n",
    "        embeddings.append(mean_hidden.cpu().numpy().flatten())  \n",
    "\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"Response: {response}\")\n",
    "    \n",
    "    post_think_match = re.search(r\"</think>\\s*(.*)\", response, re.DOTALL)\n",
    "    if not post_think_match:\n",
    "        print(\"Unable to find the </think> tag, skipping this sample.\")\n",
    "        continue\n",
    "\n",
    "    post_think_text = post_think_match.group(1)\n",
    "\n",
    "    pred_match = re.search(r\"label\\s*:\\s*(\\d+(\\.\\d+)?)\", post_think_text, re.IGNORECASE)\n",
    "    if not pred_match:\n",
    "        print(\"Failed to extract the predicted label, skipping this sample.\")\n",
    "        continue\n",
    "\n",
    "    pred_label = float(pred_match.group(1))\n",
    "    print(f\"The extracted predicted label: {pred_label}\")\n",
    "\n",
    "    \n",
    "    label_match = re.search(r\"label\\s*:\\s*(\\d+(\\.\\d+)?)\", label)\n",
    "    if not label_match:\n",
    "        print(\"Unable to extract the true label, skipping this sample.\")\n",
    "        continue\n",
    "    true_label = float(label_match.group(1))\n",
    "    print(f\"The extracted true label: {true_label}\")\n",
    "\n",
    "    y_true.append(true_label)\n",
    "    y_pred.append(pred_label)\n",
    "    true_labels.append(true_label)\n",
    "    pred_labels.append(pred_label)\n",
    "\n",
    "if not y_true or not y_pred:\n",
    "    print(\" No valid label data is available, evaluation metrics cannot be calculated.\")\n",
    "else:\n",
    "   \n",
    "    y_true_int = [int(x) for x in y_true]\n",
    "    y_pred_int = [int(x) for x in y_pred]\n",
    "\n",
    "    \n",
    "    accuracy = accuracy_score(y_true_int, y_pred_int)\n",
    "    precision = precision_score(y_true_int, y_pred_int, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_true_int, y_pred_int, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_true_int, y_pred_int, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"\\n Evaluation Results：\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "    target_names = [\"0.0\", \"1.0\", \"2.0\", \"3.0\"]\n",
    "    print(\"\\n Classification Report：\")\n",
    "    print(classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=[0.0, 1.0, 2.0, 3.0],\n",
    "        target_names=target_names,\n",
    "        zero_division=0\n",
    "    ))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0.0, 1.0, 2.0, 3.0])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues',\n",
    "                xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
